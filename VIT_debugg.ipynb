{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1d1aadd9850>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patches(x, num_patches):\n",
    "    N, C, H, W = x.shape\n",
    "    assert H == W\n",
    "\n",
    "    patches = torch.zeros(N, num_patches**2, C*H*W//num_patches**2)\n",
    "    patch_size = H//num_patches\n",
    "\n",
    "    for idx, img in enumerate(x):\n",
    "        for i in range(num_patches):\n",
    "            for j in range(num_patches):\n",
    "                patch = img[:,i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]\n",
    "                patches[idx,i*num_patches +j] = patch.flatten()\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positional_embeddings(sequence_length, d):\n",
    "    result = torch.ones(sequence_length, d)\n",
    "    for i in range(sequence_length):\n",
    "        for j in range(d):\n",
    "            result[i][j] = np.sin(i / (10000 ** (j / d))) if j % 2 == 0 else np.cos(i / (10000 ** ((j - 1) / d)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads = 2) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        head_dim = int(self.hidden_dim//self.num_heads)\n",
    "        self.head_dim = head_dim\n",
    "\n",
    "        self.q = nn.ModuleList([nn.Linear(hidden_dim, head_dim) for _ in range(self.num_heads)])\n",
    "        self.k = nn.ModuleList([nn.Linear(hidden_dim, head_dim) for _ in range(self.num_heads)])\n",
    "        self.v = nn.ModuleList([nn.Linear(hidden_dim, head_dim) for _ in range(self.num_heads)])\n",
    "\n",
    "        self.sftmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (N, P, D)\n",
    "        result = []\n",
    "        for inp in x: #(P, D)\n",
    "            inp_result = []\n",
    "            for head in range(self.num_heads):\n",
    "                q_map = self.q[head]\n",
    "                k_map = self.k[head]\n",
    "                v_map = self.v[head]\n",
    "\n",
    "                q, k, v = q_map(inp), k_map(inp), v_map(inp) # (P, HD)\n",
    "                attn = self.sftmax(q@k.T/(self.head_dim)) # (P, HD) @ (HD, P) -----> (P, P)\n",
    "                inp_result.append(attn @ v) # (P, HD)\n",
    "            result.append(torch.hstack(inp_result)) #(P, D)\n",
    "\n",
    "        return torch.cat([torch.unsqueeze(r, dim=0) for r in result]) #(N, P, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTBlock(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads, mlp_raio=4) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.mlp_ratio = mlp_raio\n",
    "\n",
    "        self.l_norm1 = nn.LayerNorm(self.hidden_dim)\n",
    "        self.mhsa = MultiHeadedAttention(hidden_dim=self.hidden_dim, num_heads=2)\n",
    "        self.l_norm2 = nn.LayerNorm(self.hidden_dim)\n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, mlp_raio*self.hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(mlp_raio*self.hidden_dim, self.hidden_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.mhsa(self.l_norm1(x)) + x\n",
    "        out = out + self.MLP(self.l_norm2(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT(nn.Module):\n",
    "    def __init__(self, img_shape = (1, 28, 28), num_patches = 7, hidden_d = 8, num_heads = 2, num_blocks=8, out_d=10) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.img_shape = img_shape\n",
    "        self.num_patches = num_patches\n",
    "        self.hidden_d = hidden_d\n",
    "        self.num_heads = num_heads\n",
    "        self.num_blocks = num_blocks\n",
    "\n",
    "        self.patch_size = self.img_shape[2]//self.num_patches\n",
    "        self.input_d = self.patch_size**2\n",
    "\n",
    "        #input to linear tokens\n",
    "        self.linear_map = nn.Linear(16, self.hidden_d)\n",
    "\n",
    "        #cls_token\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.hidden_d))\n",
    "\n",
    "        #positional embeddings\n",
    "        self.register_buffer('pos_emb', get_positional_embeddings(self.num_patches ** 2 + 1, hidden_d), persistent=False)\n",
    "        self.pos_emb.requires_grad = False\n",
    "\n",
    "        #transformer blocks\n",
    "        self.vitblocks = nn.ModuleList([ViTBlock(self.hidden_d, self.num_heads) for _ in range(self.num_blocks)])\n",
    "\n",
    "        #clf\n",
    "        self.clf = nn.Sequential(\n",
    "            nn.Linear(self.hidden_d ,out_d),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        patches = get_patches(x, self.num_patches).to(self.pos_emb.device)\n",
    "        tokens = self.linear_map(patches)\n",
    "\n",
    "        #add cls_token\n",
    "        tokens = torch.stack([torch.vstack((self.class_token, tokens[i])) for i in range(len(tokens))])\n",
    "\n",
    "        #add pos_emb\n",
    "        pos_emb = self.pos_emb.repeat(x.shape[0], 1, 1)\n",
    "        out = tokens + pos_emb\n",
    "\n",
    "        #Transformer encoder\n",
    "        for block in self.vitblocks:\n",
    "            out = block(out)\n",
    "\n",
    "        #clf token\n",
    "        out = out[:,0]\n",
    "        out = self.clf(out)    \n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit = ViT(img_shape=(1, 28, 28), num_patches=7, hidden_d=8, num_heads=2, num_blocks=8, out_d=10)\n",
    "x = torch.randn(7, 1, 28, 28)\n",
    "vit(x).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train VIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets.mnist import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data\n",
    "transform = ToTensor()\n",
    "\n",
    "train_data = MNIST(\"./datasets\",train=True, download=True, transform=transform)\n",
    "test_data = MNIST(\"./datasets\",train=False, download=True, transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, shuffle=True, batch_size=128)\n",
    "test_dataloader = DataLoader(train_data, shuffle=False, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda (NVIDIA GeForce RTX 2060)\n"
     ]
    }
   ],
   "source": [
    "#training options\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")\n",
    "\n",
    "#model\n",
    "vit = ViT(img_shape=(1, 28, 28), num_patches=7, hidden_d=8, num_heads=2, num_blocks=8, out_d=10).to(device)\n",
    "num_epochs = 10\n",
    "lr= 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 loss: 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/10 [05:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\AIML\\code\\VIT\\VIT_debugg.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/AIML/code/VIT/VIT_debugg.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m x, y \u001b[39m=\u001b[39m batch\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/AIML/code/VIT/VIT_debugg.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m x, y \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/AIML/code/VIT/VIT_debugg.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m preds \u001b[39m=\u001b[39m vit(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/AIML/code/VIT/VIT_debugg.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(preds, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/AIML/code/VIT/VIT_debugg.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mitem() \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(train_dataloader)\n",
      "File \u001b[1;32mc:\\Users\\thikj\\anaconda3\\envs\\pytorch-gpu-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\AIML\\code\\VIT\\VIT_debugg.ipynb Cell 12\u001b[0m in \u001b[0;36mViT.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/AIML/code/VIT/VIT_debugg.ipynb#X14sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/AIML/code/VIT/VIT_debugg.ipynb#X14sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     patches \u001b[39m=\u001b[39m get_patches(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_patches)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_emb\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/AIML/code/VIT/VIT_debugg.ipynb#X14sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear_map(patches)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/AIML/code/VIT/VIT_debugg.ipynb#X14sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39m#add cls_token\u001b[39;00m\n",
      "\u001b[1;32mc:\\AIML\\code\\VIT\\VIT_debugg.ipynb Cell 12\u001b[0m in \u001b[0;36mget_patches\u001b[1;34m(x, num_patches)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/AIML/code/VIT/VIT_debugg.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_patches):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/AIML/code/VIT/VIT_debugg.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m             patch \u001b[39m=\u001b[39m img[:,i\u001b[39m*\u001b[39mpatch_size:(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mpatch_size, j\u001b[39m*\u001b[39mpatch_size:(j\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mpatch_size]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/AIML/code/VIT/VIT_debugg.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m             patches[idx,i\u001b[39m*\u001b[39mnum_patches \u001b[39m+\u001b[39mj] \u001b[39m=\u001b[39m patch\u001b[39m.\u001b[39;49mflatten()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/AIML/code/VIT/VIT_debugg.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mreturn\u001b[39;00m patches\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train\n",
    "optimizer = Adam(vit.parameters(), lr=lr)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "for epoch in trange(num_epochs, desc=\"Training\"):\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1} in training\", leave=False):\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        preds = vit(x)\n",
    "        loss = criterion(preds, y)\n",
    "        train_loss += loss.detach().cpu().item() / len(train_dataloader)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} loss: {train_loss:.2f}\")\n",
    "\n",
    "# Test loop\n",
    "with torch.no_grad():\n",
    "    correct, total = 0, 0\n",
    "    test_loss = 0.0\n",
    "    for batch in tqdm(test_dataloader, desc=\"Testing\"):\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = vit(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "        test_loss += loss.detach().cpu().item() / len(test_dataloader)\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "    print(f\"Test loss: {test_loss:.2f}\")\n",
    "    print(f\"Test accuracy: {correct / total * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
